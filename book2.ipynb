{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d9031ea-9fd7-436d-a7e1-4eadf9e67d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des bibiliothèques nécessaires:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import cross_val_score, KFold, LeaveOneOut, StratifiedKFold, GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from matplotlib import pyplot\n",
    "from numpy import where\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cb8581e-9cd7-434c-9186-ab675f6686b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d74fe92d-d8bf-4a24-831c-a5a05d3c64dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de la fonction variance:\n",
    "def variance(data):\n",
    "     # Number of observations\n",
    "     n = len(data)\n",
    "     # Mean of the data\n",
    "     mean = sum(data) / n\n",
    "     # Square deviations\n",
    "     deviations = [(x - mean) ** 2 for x in data]\n",
    "     # Variance\n",
    "     variance = sum(deviations) / n\n",
    "     return variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c33d53-6cd5-4411-b56e-012f5f867cb0",
   "metadata": {},
   "source": [
    "### Preprocessing des données: voir google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cb7bdb7-4c62-42a9-a123-6085a5b1f144",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On charge le dataframe preprocessed:\n",
    "df= pd.read_csv('df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ab6a276-e3d7-4d9a-8565-3359de109fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sk_id_curr</th>\n",
       "      <th>target</th>\n",
       "      <th>code_gender</th>\n",
       "      <th>flag_own_car</th>\n",
       "      <th>flag_own_realty</th>\n",
       "      <th>cnt_children</th>\n",
       "      <th>amt_income_total</th>\n",
       "      <th>amt_credit</th>\n",
       "      <th>amt_annuity</th>\n",
       "      <th>amt_goods_price</th>\n",
       "      <th>...</th>\n",
       "      <th>instal_amt_instalment_mean</th>\n",
       "      <th>instal_amt_instalment_sum</th>\n",
       "      <th>instal_amt_payment_min</th>\n",
       "      <th>instal_amt_payment_max</th>\n",
       "      <th>instal_amt_payment_mean</th>\n",
       "      <th>instal_amt_payment_sum</th>\n",
       "      <th>instal_days_entry_payment_max</th>\n",
       "      <th>instal_days_entry_payment_mean</th>\n",
       "      <th>instal_days_entry_payment_sum</th>\n",
       "      <th>instal_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>351000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11559.247105</td>\n",
       "      <td>219625.695</td>\n",
       "      <td>9251.775</td>\n",
       "      <td>53093.745</td>\n",
       "      <td>11559.247105</td>\n",
       "      <td>219625.695</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>-315.421053</td>\n",
       "      <td>-5993.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>1129500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64754.586000</td>\n",
       "      <td>1618864.650</td>\n",
       "      <td>6662.970</td>\n",
       "      <td>560835.360</td>\n",
       "      <td>64754.586000</td>\n",
       "      <td>1618864.650</td>\n",
       "      <td>-544.0</td>\n",
       "      <td>-1385.320000</td>\n",
       "      <td>-34633.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7096.155000</td>\n",
       "      <td>21288.465</td>\n",
       "      <td>5357.250</td>\n",
       "      <td>10573.965</td>\n",
       "      <td>7096.155000</td>\n",
       "      <td>21288.465</td>\n",
       "      <td>-727.0</td>\n",
       "      <td>-761.666667</td>\n",
       "      <td>-2285.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>62947.088438</td>\n",
       "      <td>1007153.415</td>\n",
       "      <td>2482.920</td>\n",
       "      <td>691786.890</td>\n",
       "      <td>62947.088438</td>\n",
       "      <td>1007153.415</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-271.625000</td>\n",
       "      <td>-4346.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12666.444545</td>\n",
       "      <td>835985.340</td>\n",
       "      <td>0.180</td>\n",
       "      <td>22678.785</td>\n",
       "      <td>12214.060227</td>\n",
       "      <td>806127.975</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-1032.242424</td>\n",
       "      <td>-68128.0</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 313 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sk_id_curr  target  code_gender  flag_own_car  flag_own_realty  \\\n",
       "0    100002.0     1.0          0.0           0.0              0.0   \n",
       "1    100003.0     0.0          1.0           0.0              1.0   \n",
       "2    100004.0     0.0          0.0           1.0              0.0   \n",
       "3    100006.0     0.0          1.0           0.0              0.0   \n",
       "4    100007.0     0.0          0.0           0.0              0.0   \n",
       "\n",
       "   cnt_children  amt_income_total  amt_credit  amt_annuity  amt_goods_price  \\\n",
       "0           0.0          202500.0    406597.5      24700.5         351000.0   \n",
       "1           0.0          270000.0   1293502.5      35698.5        1129500.0   \n",
       "2           0.0           67500.0    135000.0       6750.0         135000.0   \n",
       "3           0.0          135000.0    312682.5      29686.5         297000.0   \n",
       "4           0.0          121500.0    513000.0      21865.5         513000.0   \n",
       "\n",
       "   ...  instal_amt_instalment_mean  instal_amt_instalment_sum  \\\n",
       "0  ...                11559.247105                 219625.695   \n",
       "1  ...                64754.586000                1618864.650   \n",
       "2  ...                 7096.155000                  21288.465   \n",
       "3  ...                62947.088438                1007153.415   \n",
       "4  ...                12666.444545                 835985.340   \n",
       "\n",
       "   instal_amt_payment_min  instal_amt_payment_max  instal_amt_payment_mean  \\\n",
       "0                9251.775               53093.745             11559.247105   \n",
       "1                6662.970              560835.360             64754.586000   \n",
       "2                5357.250               10573.965              7096.155000   \n",
       "3                2482.920              691786.890             62947.088438   \n",
       "4                   0.180               22678.785             12214.060227   \n",
       "\n",
       "   instal_amt_payment_sum  instal_days_entry_payment_max  \\\n",
       "0              219625.695                          -49.0   \n",
       "1             1618864.650                         -544.0   \n",
       "2               21288.465                         -727.0   \n",
       "3             1007153.415                          -12.0   \n",
       "4              806127.975                          -14.0   \n",
       "\n",
       "   instal_days_entry_payment_mean  instal_days_entry_payment_sum  instal_count  \n",
       "0                     -315.421053                        -5993.0          19.0  \n",
       "1                    -1385.320000                       -34633.0          25.0  \n",
       "2                     -761.666667                        -2285.0           3.0  \n",
       "3                     -271.625000                        -4346.0          16.0  \n",
       "4                    -1032.242424                       -68128.0          66.0  \n",
       "\n",
       "[5 rows x 313 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e58654-cb8b-4de2-9fa3-0d8343362a79",
   "metadata": {},
   "source": [
    "### Séparation des données:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad6bf0f0-2c6c-470a-aadf-5575891f75b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split des données en train & test\n",
    "X= df.drop(['target'],axis=1)\n",
    "y= df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4,shuffle=True, stratify=y, random_state=42)\n",
    "\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1ef785e-b71a-4df9-881d-12f6f3fbf6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 113067\n",
      "Class 1: 9929\n",
      "Proportion: 11.39 : 1\n"
     ]
    }
   ],
   "source": [
    "test_target_count = y_test.value_counts()\n",
    "print('Class 0:', test_target_count[0])\n",
    "print('Class 1:', test_target_count[1])\n",
    "print('Proportion:', round(test_target_count[0] / test_target_count[1], 2), ': 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77da6965-74ad-4077-88ea-9071a22d3102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 169598\n",
      "Class 1: 14894\n",
      "Proportion: 11.39 : 1\n"
     ]
    }
   ],
   "source": [
    "train_target_count = y_train.value_counts()\n",
    "print('Class 0:', train_target_count[0])\n",
    "print('Class 1:', train_target_count[1])\n",
    "print('Proportion:', round(train_target_count[0] / train_target_count[1], 2), ': 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c42e34-5d49-43b2-8dd2-fc7e31eda419",
   "metadata": {},
   "source": [
    "### SMOTE for unbalanced class: training set only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5bac98d-60b9-4910-be58-23f9235aed87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class distribution before SMOTE:\n",
      "Counter({0.0: 169598, 1.0: 14894})\n",
      "\n",
      "\n",
      "class distribution after SMOTE:\n",
      "Counter({0.0: 169598, 1.0: 169598})\n"
     ]
    }
   ],
   "source": [
    "# Oversample and plot imbalanced dataset with SMOTE\n",
    "# summarize class distribution\n",
    "print(\"class distribution before SMOTE:\")\n",
    "counter = Counter(y_train)\n",
    "print(counter)\n",
    "print('\\n')\n",
    "\n",
    "# transform the dataset\n",
    "oversample = SMOTE()\n",
    "X_train_s, y_train_s= oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "# summarize the new class distribution\n",
    "print(\"class distribution after SMOTE:\")\n",
    "counter = Counter(y_train_s)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f873d36b-9fe1-4185-8f58-c2f9fd086a6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16924\\33164213.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "print(stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30648ea1-dcef-41d6-b16b-ab8d9dc8f204",
   "metadata": {},
   "source": [
    "# \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d4f115-b569-420d-a25e-b1649b6137de",
   "metadata": {},
   "source": [
    "### Comparaison des modèles de classification avec cross_val_score:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f838fc-ee4d-496f-b112-159ec3a91aaa",
   "metadata": {},
   "source": [
    "#### LightGBM classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e27b12-21df-4a04-927a-a04b9087cf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM classifier:\n",
    "clf_lgbm = LGBMClassifier()\n",
    "# Validation croisée avec cross_val_score:\n",
    "# Metric:  ‘roc_auc’\n",
    "with timer(\" process cross_val_score for lgbm\"): # process cross_val_score for lgbm - done in 61s\n",
    "        scores_lgbm= cross_val_score(clf_lgbm,X_train_s, y_train_s, cv= 4, scoring='roc_auc') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3b6d43-aea7-4eb4-9e01-c06471c037c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores_lgbm) # [0.88162016 0.99997028 0.99998038 0.99996053]\n",
    "print(scores_lgbm.mean()) # 0.9703828383557017\n",
    "print(variance(scores_lgbm)) # 0.0026262712086987383"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6c9a07-afac-4a0c-a2a0-2dc6d2305609",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Classifier: "
   ]
  },
  {
   "cell_type": "raw",
   "id": "77f36ed3-768d-4de1-9ab6-470abe2a1df7",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier # HistGradientBoostingClassifier FASTER FOR LARGE SAMPLES\n",
    "\n",
    "#clf_xgb= GradientBoostingClassifier(max_features= 'log2')\n",
    "#process cross_val_score for xgb - done in 342s\n",
    "#[0.87237321 0.99936311 0.99935889 0.9992222 ]\n",
    "#0.9675793521462993\n",
    "#0.0030214061820368976\n",
    "\n",
    "#clf_xgb= GradientBoostingClassifier(max_features= 'sqrt')\n",
    "# process cross_val_score for xgb - done in 626s\n",
    "#[0.87243582 0.99948681 0.99961232 0.99966911]\n",
    "#0.9678010162024336\n",
    "#0.003031511055784114\n",
    "\n",
    "clf_xgb= GradientBoostingClassifier()\n",
    "#process cross_val_score for xgb - done in 5706s (env 96min)\n",
    "#[0.87529565 0.99992271 0.99993919 0.99994977]\n",
    "#0.9687768301317181\n",
    "#0.0029129103424552654"
   ]
  },
  {
   "cell_type": "raw",
   "id": "42b8ed99-27ef-4e77-a381-e587bb79848e",
   "metadata": {},
   "source": [
    "# Validation croisée avec cross_val_score:\n",
    "with timer(\" process cross_val_score for xgb\"):\n",
    "        scores_xgb= cross_val_score(clf_xgb,X_train_s, y_train_s, cv= 4, scoring='roc_auc') \n",
    "print(scores_xgb) \n",
    "print(scores_xgb.mean()) \n",
    "print(variance(scores_xgb)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da30559-10b7-4427-9fc2-045ced160fed",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fc0c5d89-8aff-493d-9779-6ef35e0e338b",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed8d501e-2c7f-4cf9-a5b1-aa7139c0bab8",
   "metadata": {},
   "source": [
    "# Validation croisée avec cross_val_score:\n",
    "with timer(\" process cross_val_score for rf\"): # process cross_val_score for rf - done in 929s (env 17min)\n",
    "        scores_rf= cross_val_score(clf_rf,X_train_s, y_train_s, cv= 4, scoring='roc_auc')\n",
    "print(scores_rf) # [0.93448035 0.99999919 0.9999995  0.99999898]\n",
    "print(scores_rf.mean()) # 0.9836195039754854\n",
    "print(variance(scores_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bae477-c233-4149-83a3-c2246ea04bbb",
   "metadata": {},
   "source": [
    "* On choisit le LightGBM classifier principalement pour son fit time comparé aux autres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102ed5c0-ce9a-4384-ba8a-afd326e7dbf5",
   "metadata": {},
   "source": [
    "### Optimisation des hyperparamètres du modèle le LightGBM classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14e3a801-cb45-43f0-918a-f0936b126b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimisation avec hyperopt\n",
    "from hyperopt import fmin, tpe, hp, anneal, Trials\n",
    "from random import *\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "    \n",
    "def lgbm_cv(params):\n",
    "    \n",
    "    params = {'n_estimators': params['n_estimators'], \n",
    "              'learning_rate': params['learning_rate'], \n",
    "              'num_leaves': params['num_leaves'],\n",
    "              'colsample_bytree': params['colsample_bytree'],\n",
    "              'subsample': params['subsample'],\n",
    "              'min_child_weight': params['min_child_weight']\n",
    "                }\n",
    "    \n",
    "      #'reg_alpha': params['reg_alpha'],\n",
    "            #  'reg_lambda': params['reg_lambda'],\n",
    "            \n",
    "    # we use this params to create a new LGBM Regressor\n",
    "    model = LGBMClassifier(**params)\n",
    "    \n",
    "    # and then conduct the cross validation with the same folds as before\n",
    "    \n",
    "    score = -cross_val_score(model, X_train_s,y_train_s, cv=4, scoring= 'roc_auc' , n_jobs=-1).mean()\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d8db50-8d41-4602-a63e-17c3ec01cf54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [19:58<11:34, 38.58s/trial, best loss=?]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from random import *\n",
    "\n",
    "# possible values of parameters\n",
    "space={'n_estimators': hp.choice('n_estimators', [1e3,1e4,1e5]), \n",
    "        'learning_rate': hp.choice('learning_rate', [1e-3,1e-2,1e-1,1]),\n",
    "        'num_leaves': hp.choice('num_leaves', [5,15,25,35,45,60,75]),  \n",
    "        'colsample_bytree': hp.choice('colsample_bytree', [0.1,0.4,0.7,0.9,1]), \n",
    "        'subsample': hp.choice('subsample', [0.1,0.4,0.7,0.9,1]),\n",
    "        'min_child_weight' : hp.choice('min_child_weight', [1e-5,1e-4,1e-3,1e-2,1e-1])\n",
    "      }\n",
    "\n",
    "  #'reg_alpha': hp.uniform('reg_alpha', 0, 100),\n",
    " #'reg_lambda': hp.uniform('reg_lambda', 0, 100),\n",
    "\n",
    "#trials will contain logging information\n",
    "trials = Trials()\n",
    "\n",
    "best=fmin(lgbm_cv, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          max_evals= 50, # maximum number of iterations\n",
    "          trials=trials, # logging\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e84c5fd-8413-4d5a-8cec-1702787265f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing the score on the test set\n",
    "model = LGBMClassifier( n_estimators= best['n_estimators'], \n",
    "              learning_rate= best['learning_rate'], \n",
    "              num_leaves= int(best['num_leaves']),\n",
    "              colsample_bytree= best['colsample_bytree'],\n",
    "              subsample= best['subsample'],\n",
    "              min_child_weight= best['min_child_weight']\n",
    "                      )\n",
    "             #reg_alpha=  best['reg_alpha'],\n",
    "              #reg_lambda= best['reg_lambda'],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab99057-1354-479b-b31f-732f8d816302",
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer(\" process fit for lgbm\"): #  process fit for lgbm - done in 1175s (20min)\n",
    "        lgbm.fit(X_train_s,y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d748fa9d-dacd-40dc-9376-53a685497781",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lgbm= lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6125caf9-2cde-47a5-886f-e23e547b6969",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['Class 0', 'Class 1']\n",
    "print(classification_report(y_test, pred_lgbm, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb66b869-0600-4a9d-9f84-2817e55fc2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, pred_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b304317a-c593-497d-9555-fb058de29c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5921d4-7afd-46b6-9e24-9a7fdf80bfda",
   "metadata": {},
   "source": [
    "# ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e65f52-c7d1-4605-bade-e510d4c1dd9c",
   "metadata": {},
   "source": [
    "### Optimisation des hyperparamètres avec un scoring métier:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dbbf00-1593-45f2-a29c-a6dd64884caa",
   "metadata": {},
   "source": [
    "#### Application de hyperopt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99408af7-9789-49d0-a565-63d25d8fb730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, anneal, Trials\n",
    "from random import *\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "    \n",
    "def lgbm_cv(params):\n",
    "    \n",
    "    params = {'num_leaves': int(params['num_leaves']), \n",
    "              'min_child_weight': params['min_child_weight'], \n",
    "             'subsample': params['subsample'],\n",
    "              'colsample_bytree': params['colsample_bytree'],\n",
    "             'reg_alpha': params['reg_alpha'],\n",
    "             'reg_lambda': params['reg_lambda']\n",
    "             }\n",
    "    \n",
    "    # we use this params to create a new LGBM Regressor\n",
    "    model = LGBMClassifier(**params)\n",
    "    \n",
    "    # and then conduct the cross validation with the same folds as before\n",
    "    fbeta_scorer = make_scorer(fbeta_score, beta=3) # beta=3\n",
    "    score = -cross_val_score(model, X_train_s,y_train_s, cv=4, scoring= fbeta_scorer, n_jobs=-1).mean()\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aa2a0e-3117-4e88-b3f9-43a9f00f664a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from random import *\n",
    "\n",
    "# possible values of parameters\n",
    "space={'num_leaves': int(hp.quniform('num_leaves', 10, 70, 1)),\n",
    "       'min_child_weight' : hp.quniform('min_child_weight', 1e-5, 1e4, 1),\n",
    "       'subsample' : hp.quniform('subsample', 0.5, 1, 1),\n",
    "       'colsample_bytree' : hp.quniform('colsample_bytree', 0.5, 1, 1),\n",
    "       'reg_alpha' : hp.quniform('reg_alpha', 0, 100, 1),\n",
    "       'reg_lambda' : hp.quniform('reg_lambda', 0, 100, 1),\n",
    "      }\n",
    "\n",
    "# trials will contain logging information\n",
    "trials = Trials()\n",
    "\n",
    "best=fmin(lgbm_cv, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          max_evals= 50, # maximum number of iterations\n",
    "          trials=trials, # logging\n",
    "         )\n",
    "\n",
    "\n",
    "# computing the score on the test set\n",
    "model = LGBMClassifier( n_estimators=10000, num_leaves= best['num_leaves'], min_child_weight= best['min_child_weight'],\n",
    "                       subsample= best['subsample'], colsample_bytree= best['colsample_bytree'],\n",
    "                       reg_alpha= best['reg_alpha'], reg_lambda= best['reg_lambda'])\n",
    "\n",
    "# Wall time: 1h 7min 38s\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370d22b2-f54f-4094-807c-5bfd2972748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best score {:.3f} params {}\".format( lgbm_cv(best), best))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2cddc1ec-af4f-4cd8-b97a-1f70c17f0ec5",
   "metadata": {},
   "source": [
    "print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b88540-d8c1-4557-96ab-b0b71fca68a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = LGBMClassifier( n_estimators=10000, colsample_bytree= 1.0, min_child_weight= 9924, \n",
    "#        num_leaves= 39, reg_alpha= 5.0, reg_lambda= 86.0, subsample= 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eccfdd-863a-4c92-9657-2380494deebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer(\" process model fit\"): # process model fit - done in 656s (11 min)\n",
    "        model.fit(X_train_s,y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87fba8a-0c5e-48ee-835d-2263b8350510",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lgbm= model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaadf5bb-7566-4dc2-ab83-6697769d7169",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['Class 0', ' Class 1']\n",
    "print(classification_report(y_test, pred_lgbm, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e46a718-25de-46f6-8594-03c96d9c79e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, pred_lgbm,labels= [0,1])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e6ce0305-2675-4616-bf66-34a1d16da0a6",
   "metadata": {},
   "source": [
    "# Avec GridSearchCV :\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "\n",
    "fbeta_scorer = make_scorer(fbeta_score, beta=3) # beta=3\n",
    "param_test ={'num_leaves': [10, 30, 50,70], \n",
    "             'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "             'subsample': [0.6, 0.7, 0.8, 0.9, 1],\n",
    "             'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1],\n",
    "             'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n",
    "             'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}\n",
    "\n",
    "#n_estimators is set to a \"large value\". The actual number of trees build will depend on early stopping and 10000 define only the absolute maximum\n",
    "lgbm_ = LGBMClassifier(max_depth=-1, random_state=314, silent=True, metric='None', n_jobs=4, n_estimators=10000)\n",
    "\n",
    "grid_lgbm = GridSearchCV(lgbm_, param_grid= param_test, scoring=fbeta_scorer, cv= 4, n_jobs=-1, refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7effffee-9fcc-40ec-bfb2-55ecdcfa19d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3875fe-edaa-4bcc-951f-a9507b6fbc5d",
   "metadata": {},
   "source": [
    "### Features importance"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a0d8b5d1-4d42-4679-9c08-111d957e5b7e",
   "metadata": {},
   "source": [
    "feats = [f for f in X_train_s.columns]\n",
    "df_importance = pd.DataFrame()\n",
    "df_importance[\"Feature\"] = feats\n",
    "df_importance[\"Importance\"] = model.feature_importances_\n",
    "# zip à faire pour respecter les index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca984f96-b5ce-40fa-8dc9-1aeb0d3ae10e",
   "metadata": {},
   "source": [
    "df_importance.sort_values(by= 'Importance', ascending= False).head(20)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f5ac643c-6d53-4f5f-96d3-10f42f763726",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "#do code to support model\n",
    "#\"data\" is the X dataframe and model is the SKlearn object\n",
    "\n",
    "feats = {} # a dict to hold feature_name: feature_importance\n",
    "for feature, importance in zip(data.columns, model.feature_importances_):\n",
    "    feats[feature] = importance #add the name/value pair \n",
    "\n",
    "importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-importance'})\n",
    "importances.sort_values(by='Gini-importance').plot(kind='bar', rot=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224167df-1eb7-4627-b535-863c0c2ba99e",
   "metadata": {},
   "source": [
    "### Features importance with LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0be10ab-1c97-4578-a5b6-dd409fea4f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime \n",
    "from lime import lime_tabular\n",
    "\n",
    "#single instance from the test set. We will use it to make explanations with LIME \n",
    "#idx = random.randint(1, len(X_test))\n",
    "test_1 = X_test.iloc[1] # y_test.iloc[1] == 0\n",
    "\n",
    "lime_explainer = lime_tabular.LimeTabularExplainer( training_data=np.array(X_train_s), feature_names=X_train_s.columns,\n",
    "                                                    class_names=['0', '1'], mode='classification')\n",
    "                                                                        \n",
    "lime_exp = lime_explainer.explain_instance(data_row=test_1, predict_fn=model.predict_proba)\n",
    "\n",
    "lime_exp.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3393aab1-0933-499c-b9aa-fb9fc221b28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime \n",
    "from lime import lime_tabular\n",
    "\n",
    "#single instance from the test set. We will use it to make explanations with LIME \n",
    "test_2 = X_test.iloc[180] # y_test.iloc[180]== 1\n",
    "\n",
    "lime_explainer = lime_tabular.LimeTabularExplainer( training_data=np.array(X_train_s), feature_names=X_train_s.columns,\n",
    "                                                    class_names=['0', '1'], mode='classification')\n",
    "                                                                        \n",
    "lime_exp = lime_explainer.explain_instance(data_row=test_2, predict_fn=model.predict_proba)\n",
    "\n",
    "lime_exp.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2334e7b1-fb23-4d7e-ab65-55661eee59ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_exp.predict_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77180c4-0e89-4019-b4f6-6370b0d8e8a3",
   "metadata": {},
   "source": [
    "#### Feature Importances using \"as_pyplot_figure()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1ab868-2681-42cd-b163-056315a226c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(\"ggplot\"):\n",
    "    lime_exp.as_pyplot_figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e80b31-2e71-4cc5-8f64-94a5642e8840",
   "metadata": {},
   "source": [
    "#### Retrieve Features Importances as List using \"as_list()\": "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad0f439-d258-41da-9efd-10a8d9e0ed72",
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_exp.as_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5fc55a-4700-4e6c-ad33-3d59521b5c2b",
   "metadata": {},
   "source": [
    "#### Retrieve Features Importances as Dictionary using \"as_map()\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6ba65e-e6ad-4efb-a91c-2e1567587918",
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_exp.as_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48955004-f48f-4f98-96b0-a89061f696e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve Average Local and Global Prediction Value:\n",
    "print(\"Explanation Local Prediction  : \", lime_exp.local_pred)\n",
    "print(\"Explanation Global Prediction : \", lime_exp.predict_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f186df3-23cd-4f39-b9da-7ec4500ac9d2",
   "metadata": {},
   "source": [
    "#### Visualize Features Importances for Wrong Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0143056-0e5c-4b94-a26f-1b37c4427ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "false_preds = np.argwhere((preds != y_test.to_numpy())).flatten()\n",
    "\n",
    "idx  = random.choice(false_preds)\n",
    "\n",
    "#print(\"Prediction : \", breast_cancer.target_names[model.predict(X_test[idx].reshape(1,-1))[0]])\n",
    "#print(\"Actual :     \", breast_cancer.target_names[Y_test[idx]])\n",
    "\n",
    "explanation = lime_explainer.explain_instance(X_test.iloc[idx], model.predict_proba)\n",
    "\n",
    "explanation.show_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee6a405-03b1-42f5-ab0f-632f1640d482",
   "metadata": {},
   "source": [
    "* Piste d'amélioration du modèle: écarter les features avec forte contribution dans les FP:\n",
    "\n",
    "(organization_type_legal_services), (organization_type_industry_type_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61161ece-0167-4128-8f21-468b51bd61ff",
   "metadata": {},
   "source": [
    "### SHAP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a3756d-d353-4bf0-befe-ef8b8426bbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12d82e2-fdc5-4115-b6e0-cb69e21bc474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we use the Tree SHAP implementation integrated into Light GBM to explain the entire dataset:\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e358effa-71da-47e9-b37c-d64b3d197b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a single prediction:\n",
    "shap.force_plot(explainer.expected_value[1], shap_values[1][0,:], X_test.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ce20f5-9fd4-4479-8a6c-f0da3a2c849e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize many predictions: we only visualize 100 individuals.\n",
    "#  Impact of the individual feature on all 100 predictions. \n",
    "#In this chart, y-axis values represent predicted values for each sample and the x-axis represents 10 samples from 0-9.\n",
    "shap.force_plot(explainer.expected_value[1], shap_values[1][:100,:], X_test.iloc[:100,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dfa62d-cdd3-43e5-a038-667ca64a91ee",
   "metadata": {},
   "source": [
    "* SHAP Summary Plot: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018ea6d2-64e9-4824-b89e-435efef03680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Summary Plot: \n",
    "# we use a density scatter plot of SHAP values for each feature to identify how much impact \n",
    "#each feature has on the model output for individuals in the validation dataset.\n",
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc717aae-784c-43da-b2a0-a8853c24b6dc",
   "metadata": {},
   "source": [
    "### Serialisatin du modèle avec Joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67049329-6591-4bdd-adc5-285d1d19e162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the library\n",
    "import joblib\n",
    "model_lgbm= model\n",
    "# set the output object name\n",
    "filename = 'model.joblib'\n",
    "# serialize (save) the object, in this case \"model\"\n",
    "joblib.dump(model_lgbm, filename)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0853fdee-0f5b-43a5-af7b-ca4896130474",
   "metadata": {},
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "\n",
    "gauth = GoogleAuth()           \n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "upload_file = ['model.joblib']\n",
    "gfile = drive.CreateFile({'parents': [{'id': '1kSV4TcTb87fmCMrlVr_jK1z9BgRNjb83'}]})\n",
    "#Read file and set it as the content of this instance.\n",
    "gfile.SetContentFile(upload_file)\n",
    "gfile.Upload() # Upload the file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7835fefb-08e9-47ea-bab2-f81a39dd675b",
   "metadata": {},
   "source": [
    "### Création de l'API avec MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c94b38-2266-4eb1-8758-4054cc397810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.models.signature import infer_signature\n",
    "signature = infer_signature(X_train_s, y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c473780b-30cd-4671-aafc-ad34c0e93f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "mlflow.lightgbm.save_model(model, 'lgbm_model', signature=signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6711a6-81bc-4f9a-b18a-be37a096b0ee",
   "metadata": {},
   "source": [
    "* Déploiement d'une API REST depuis le terminal:\n",
    " mlflow models serve -m C:/Users/marat/Downloads/Py-DS-ML-Bootcamp-master/OCR/P7/lgbm_model/ \n",
    "\n",
    "* Requête curl pour envoyer une requête:\n",
    "** curl http://127.0.0.1:5000/invocations -H 'Content-Type: application/json' -d '{\"data\": [[x, y, z,etc]]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f230bf63-876a-46d6-bac1-ce6482330b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "* Avec la console, depuis le répertoire racine, lancer Streamlit avec la commande:\n",
    "streamlit run C:/Users/marat/Downloads/Py-DS-ML-Bootcamp-master/OCR/P7/dashboard.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
